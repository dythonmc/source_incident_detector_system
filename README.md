# **Sistema de Detecci√≥n de Incidencias con Agentes de IA**
<br>

## **1. Resumen del Proyecto**
Este proyecto implementa un pipeline automatizado de extremo a extremo para el monitoreo, detecci√≥n y an√°lisis de incidencias en el procesamiento de archivos. El sistema est√° construido como una arquitectura multi-agente donde diferentes agentes especializados, construidos con el framework `google-adk`, colaboran para cumplir el objetivo.

El dise√±o se basa en un enfoque h√≠brido: se utiliza l√≥gica determin√≠stica para tareas que requieren una precisi√≥n del 100% (el motor de detecci√≥n), mientras que se delegan a los **agentes de IA** las tareas que involucran razonamiento, comprensi√≥n de lenguaje no estructurado y generaci√≥n de contenido cualitativo.

<br>

**Diagrama Dise√±o**
![Diagrama de Arquitectura del Sistema de Detecci√≥n de Incidencias](docs/architecture.svg)


## **2. Arquitectura Multi-Agente**
El sistema no es una aplicaci√≥n monol√≠tica, sino un ecosistema de agentes que se orquestan para realizar tareas complejas. Cada agente tiene una √∫nica responsabilidad, lo que hace que el sistema sea modular, escalable y f√°cil de mantener.

**El flujo del pipeline est√° orquestado por la colaboraci√≥n de los siguientes agentes:**

### 2.1. Agentes de Operacion.
`DataMinerAgent`:

- **Rol:** El Extractor de Conocimiento.

- **Tarea:** Su misi√≥n es leer los documentos CV de cada fuente, que est√°n en formato Markdown semi-estructurado, y extraer los patrones clave (horarios, vol√∫menes esperados, etc.).

- **Capacidades (Tools):** Est√° equipado con una FunctionTool que le permite leer el contenido de los archivos del sistema.

- **Resultado:** Produce el cv_data.json, que sirve como la "memoria" o base de conocimiento para el resto del sistema.

`RecommenderAgent`:

- **Rol:** El Analista de Operaciones.

- **Tarea:** Recibe una incidencia t√©cnica (datos estructurados) y el contexto de la fuente (del cv_data.json). Su objetivo es razonar sobre el problema y generar una recomendaci√≥n clara y √∫til en lenguaje natural para el equipo de operaciones.

- **Capacidades (Tools):** No utiliza herramientas externas. Su valor reside puramente en su capacidad de razonamiento y generaci√≥n de lenguaje (LLM).

- **Resultado:** Enriquece el reporte de incidencias con una capa de inteligencia accionable.

### 2.2. Agentes de Evaluaci√≥n.
Una parte fundamental del dise√±o es la capacidad del sistema para auto-evaluarse. Para ello, hemos construido un framework de evaluaci√≥n que tambi√©n se basa en agentes.

`DataMinerEvaluator`:

- **Rol:** El Auditor de Precisi√≥n.

- **Tarea:** Este pipeline de evaluaci√≥n ejecuta el `DataMinerAgent` sobre un caso de prueba y compara su salida JSON campo por campo contra un "ground truth" (un JSON perfecto creado manualmente).

- **Resultado:** Genera un reporte con m√©tricas de **Precisi√≥n y Completitud**, y crea un log (evaluation_log.json) para rastrear el rendimiento del agente a lo largo del tiempo.

`RecommenderEvaluatorAgent`:

- **Rol:** El Juez de Calidad.

- **Tarea:** Implementa el patr√≥n avanzado `"LLM-as-a-Judge"`. Este agente recibe una incidencia, una recomendaci√≥n "ideal" (ground truth) y la recomendaci√≥n generada por el `RecommenderAgent`.

- **Capacidades (Tools):** No usa herramientas; su funci√≥n es el razonamiento cualitativo.

- **Resultado:** Emite un veredicto en formato JSON que incluye **una puntuaci√≥n de calidad (de 1 a 5)** y una justificaci√≥n de por qu√© la recomendaci√≥n del `RecommenderAgent` fue buena o mala. Este resultado tambi√©n se registra en un log.

`FeedbackEvaluatorAgent`:

- **Rol:** El Analista de Feedback.

- **Tarea:** Compara el reporte de incidencias completo de nuestro sistema con el feedback semi-estructurado proporcionado por los stakeholders humanos.

- **Capacidades (Tools):** Est√° equipado con una `FunctionTool` (`parse_feedback_excel_file`) que le permite leer y estructurar el archivo de feedback.

- **Resultado:** Genera un **plan de acci√≥n de mejora** en formato JSON, identificando posibles falsos positivos o falsos negativos y sugiriendo d√≥nde se debe refinar la l√≥gica de los detectores.

<br>

## **3. Paso a Paso del Flujo del Sistema**
***FASE DE PIPELINE (Ejecuci√≥n de Producci√≥n)***

**Paso 1: Preparaci√≥n y Extracci√≥n de Conocimiento**

- **1.1: Recolecci√≥n de Datos Crudos:** Se toman los ``files.json``, la carpeta ``datasource_cvs/`` y el archivo ``Feedback.xlsx.``

- **1.2: Carga con data_loader:** El m√≥dulo ``src/preparation/data_loader.py`` carga los datos de operaci√≥n (``files.json``) en un DataFrame.

- **1.3: ``DataMinerAgent`` extrae la Inteligencia:** El ``DataMinerAgent`` lee los archivos ``.md`` no estructurados y los transforma en el archivo ``outputs/cv_data.json``, que es la base de conocimiento del sistema.

**Paso 2: Detecci√≥n Determin√≠stica de Incidencias**

- **2.1: El Motor L√≥gico se Activa:** El script ``run_incident_detection.py`` itera sobre cada fuente conocida.

- **2.2: Cruce de Datos vs. Inteligencia:** El m√≥dulo ``src/detection/detectors.py`` aplica 6 reglas de negocio precisas, comparando los datos del d√≠a con los patrones del ``cv_data.json.``

- **2.3: Salida T√©cnica:** Se genera el reporte ``outputs/{fecha}_incidents_report.json`` con una lista estructurada de todos los problemas encontrados.

**Paso 3: Enriquecimiento y Reporte Ejecutivo con IA**

- **3.1: Clasificaci√≥n de Severidad:** El m√≥dulo ``src/reporting/consolidator.py`` lee el reporte de incidencias y asigna un nivel de criticidad (üî¥ URGENTE, üü° REQUIERE ATENCI√ìN, TODO BIEN üü¢) a cada fuente.

- **3.2: ``RecommenderAgent`` Genera Insights:** El ``RecommenderAgent`` analiza cada incidencia y, bas√°ndose en el contexto del CV, genera una recomendaci√≥n accionable en lenguaje natural.

- **3.3: Salida Ejecutiva:** Se generan los reportes finales en ``outputs/``: un ``.md`` para humanos y un .``json`` para otros sistemas.

**Paso 4: Notificaci√≥n (Bonus)**

- **4.1: Env√≠o de Alerta:** El m√≥dulo ``src/notifications/email_sender.py`` toma el reporte .md, lo convierte a HTML y lo env√≠a por email a los stakeholders.

<br>

## **4. Estructura del Proyecto**
El proyecto sigue una estructura profesional que separa claramente los intereses (Separation of Concerns):

```
/
‚îú‚îÄ‚îÄ src/              # C√≥digo fuente de la aplicaci√≥n (m√≥dulos reutilizables).
|   |‚îÄ‚îÄ agents/       # Agentes de operacion y evaluaci√≥n.
‚îú‚îÄ‚îÄ scripts/          # Scripts ejecutables (puntos de entrada).
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/     # Scripts que forman el pipeline de producci√≥n.
‚îÇ   ‚îî‚îÄ‚îÄ evaluation/   # Scripts para evaluar la calidad de los agentes.
‚îú‚îÄ‚îÄ data/             # Datos de entrada crudos.
‚îú‚îÄ‚îÄ outputs/          # Archivos generados por el pipeline (reportes, JSONs).
‚îú‚îÄ‚îÄ evaluation/       # "Ground truth" y logs de las evaluaciones.
‚îú‚îÄ‚îÄ .env              # Archivo para variables de entorno (API |Keys, credenciales).
‚îî‚îÄ‚îÄ requirements.txt  # Dependencias del proyecto.
```

<br>

## **5. Gu√≠a de Instalaci√≥n**
Sigue estos pasos para configurar el entorno de desarrollo.

1. **Clonar el Repositorio:**
```
git clone <URL_DEL_REPOSITORIO>
cd <NOMBRE_DEL_REPOSITORIO>
```
2. **Crear y Activar el Ambiente Virtual:**

```
python -m venv venv
# En Windows
.\venv\Scripts\activate
# En macOS/Linux
source venv/bin/activate
```
3. **Instalar Dependencias:**
Aseg√∫rate de tener todas las librer√≠as necesarias instaladas ejecutando:

```
pip install -r requirements.txt
```
4. **Configurar Variables de Entorno:**
Crea un archivo .env en la ra√≠z del proyecto, a√±adiendo tus propias claves:

```
# Clave para los agentes de IA de Google
GOOGLE_API_KEY="tu_api_key_de_google"

# Credenciales para el env√≠o de email (se recomienda usar una Contrase√±a de Aplicaci√≥n)
EMAIL_SENDER="tu_correo@ejemplo.com"
EMAIL_PASSWORD="tu_contrase√±a_de_aplicacion"
EMAIL_RECIPIENT="correo_destino@ejemplo.com"
```

<br>

## 6. **Gu√≠a de Uso del Sistema**
Ejecutar el Pipeline Completo
Para ejecutar todo el proceso de forma autom√°tica para un d√≠a espec√≠fico, configura la fecha en el script principal y ejec√∫talo desde la ra√≠z del proyecto.

1. Abre el archivo `run_pipeline.py`.

2. Modifica la variable `OPERATION_DATE_STR` a la fecha deseada.

3. Ejecuta el script:

```
python run_pipeline.py
```

Esto ejecutar√° la miner√≠a de datos (si es necesario), la detecci√≥n, la generaci√≥n de reportes y el env√≠o de la notificaci√≥n por email.

**Ejecutar M√≥dulos Individualmente**

Para desarrollo y depuraci√≥n, puedes ejecutar cada fase del pipeline y las evaluaciones de forma independiente usando el modo m√≥dulo de Python (`-m`). **Aseg√∫rate de ejecutar estos comandos desde la ra√≠z del proyecto.**

- **Fase 1: Miner√≠a de Datos:**

```
python -m scripts.pipeline.run_data_mining
```

- **Fase 2: Detecci√≥n de Incidencias:**
```
python -m scripts.pipeline.run_incident_detection
```
- **Fase 3: Reporte Ejecutivo:**

```
python -m scripts.pipeline.run_final_report
```

- **Bonus: Enviar Notificaci√≥n:**

```
python -m scripts.pipeline.run_send_report
```
#### **Ejecutar las Evaluaciones de Agentes**
- **Evaluar el `DataMinerAgent` (Precisi√≥n de Extracci√≥n):**

```
python -m scripts.evaluation.run_dataminer_evaluation
```
- **Evaluar el `RecommenderAgent` (Calidad de Recomendaci√≥n):**

```
python -m scripts.evaluation.run_recommender_evaluation
```
- **Evaluar el Sistema vs. Feedback Humano:**
```
python -m scripts.evaluation.run_feedback_evaluation
```

## **7. Componentes Clave y Dise√±o**
- **Dise√±o H√≠brido:** El sistema combina l√≥gica determin√≠stica para tareas que requieren 100% de precisi√≥n (detecci√≥n de incidencias) con Agentes de IA para tareas que involucran lenguaje no estructurado y razonamiento (miner√≠a de CVs, recomendaciones).

- **Framework de Agentes ``google-adk``:** Se utiliza para definir agentes especializados y modulares, cada uno con un prop√≥sito claro y, en su caso, herramientas espec√≠ficas.

- **Framework de Evaluaci√≥n Continua:** El proyecto incluye un robusto sistema de evaluaci√≥n que permite medir la calidad de cada componente de IA de forma cuantitativa y cualitativa, sentando las bases para la mejora continua y MLOps.

